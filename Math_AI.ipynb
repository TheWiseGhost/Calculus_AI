{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheWiseGhost/Calculus_AI/blob/main/Math_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zkvYxNOeLKQE"
      },
      "outputs": [],
      "source": [
        "# Creating a Math AI that can solve calculus problems\n",
        "\n",
        "# Exploring a few models, older models and experiments are shown\n",
        "# as you scroll to the bottom of the page\n",
        "\n",
        "# Started 1/22/25\n",
        "# Aditya Byju"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Net"
      ],
      "metadata": {
        "id": "_z-kwS3YuJQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "import random\n",
        "\n",
        "# Function to generate random calculus problems\n",
        "def generate_calculus_problems(num_problems=100):\n",
        "    data = []\n",
        "    for _ in range(num_problems):\n",
        "        # Random polynomial function\n",
        "        x = sp.symbols('x')\n",
        "        degree = random.randint(1, 3)  # Degree of the polynomial\n",
        "        coefficients = [random.randint(-10, 10) for _ in range(degree + 1)]\n",
        "        poly = sum(c * x**i for i, c in enumerate(coefficients))\n",
        "\n",
        "        # Randomly choose between differentiation or integration\n",
        "        if random.choice(['diff', 'integrate']) == 'diff':\n",
        "            problem = f\"d/dx({poly})\"\n",
        "            solution = sp.diff(poly, x)\n",
        "        else:\n",
        "            problem = f\"∫({poly})dx\"\n",
        "            solution = sp.integrate(poly, x)\n",
        "\n",
        "        data.append((str(problem), str(solution) + \" + C\" if '∫' in problem else str(solution)))\n",
        "\n",
        "    return data\n",
        "\n",
        "# Generate and save dataset\n",
        "problems = generate_calculus_problems(10000)\n"
      ],
      "metadata": {
        "id": "cerY8l4gul5K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Create a vocabulary dictionary, ensuring we include the needed symbols.\n",
        "vocab = defaultdict(lambda: len(vocab))\n",
        "\n",
        "# Add special symbols to the vocabulary (such as x, operators, etc.)\n",
        "for token in ['x', '+', '-', '*', '/', '(', ')', '∫', 'd/dx', 'dx']:\n",
        "    vocab[token]  # Ensure these tokens are in the vocab\n",
        "\n",
        "# Add all symbols in the dataset to the vocabulary\n",
        "def update_vocab_with_data(data):\n",
        "    for problem, solution in data:\n",
        "        for token in problem.split():\n",
        "            vocab[token]  # Add tokens from the problem to the vocab\n",
        "        for token in solution.split():\n",
        "            vocab[token]  # Add tokens from the solution to the vocab\n",
        "\n",
        "# Call this function to ensure the vocab is updated\n",
        "update_vocab_with_data(problems)\n",
        "\n",
        "def tokenize_expression(expression):\n",
        "    return [vocab[token] for token in expression.replace('(', ' ( ').replace(')', ' ) ').split() if token in vocab]\n",
        "\n",
        "\n",
        "class CalculusDataset(Dataset):\n",
        "    def __init__(self, data, vocab, max_length=50):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        problem, solution = self.data[idx]\n",
        "        # Tokenize the problem and solution\n",
        "        input_ids = torch.tensor(tokenize_expression(problem))\n",
        "        target_ids = torch.tensor(tokenize_expression(solution))\n",
        "\n",
        "        # Padding the sequences to the maximum length\n",
        "        input_ids = torch.cat([input_ids, torch.zeros(self.max_length - len(input_ids))], dim=0)[:self.max_length]\n",
        "        target_ids = torch.cat([target_ids, torch.zeros(self.max_length - len(target_ids))], dim=0)[:self.max_length]\n",
        "\n",
        "        return input_ids.long(), target_ids.long()\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        input_batch = [item[0] for item in batch]\n",
        "        target_batch = [item[1] for item in batch]\n",
        "        input_batch = pad_sequence(input_batch, batch_first=True, padding_value=0)  # Padding input\n",
        "        target_batch = pad_sequence(target_batch, batch_first=True, padding_value=0)  # Padding target\n",
        "        return input_batch, target_batch\n",
        "\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = CalculusDataset(problems, vocab)\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=CalculusDataset.collate_fn)"
      ],
      "metadata": {
        "id": "CO4LynMkuqAM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.encoder(x)\n",
        "        rnn_out, (hidden, cell) = self.rnn(embedded)\n",
        "        output = self.decoder(rnn_out)\n",
        "        return output\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "input_size = len(vocab)  # Number of tokens in vocabulary\n",
        "hidden_size = 256        # Number of hidden units in the RNN\n",
        "output_size = len(vocab) # Output size is the same as the input size (for token prediction)\n",
        "\n",
        "model = Seq2SeqModel(input_size, hidden_size, output_size)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "jh_rNfm-ushf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for input_ids, target_ids in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_ids)\n",
        "\n",
        "        # Compute the loss\n",
        "        output = output.view(-1, output_size)\n",
        "        target_ids = target_ids.view(-1)\n",
        "        loss = loss_fn(output, target_ids)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzvUwiC4uv56",
        "outputId": "cecef523-ebdb-4e2b-d7d3-cf8539a31555"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.2422828232884407\n",
            "Epoch [2/5], Loss: 0.18427832058668137\n",
            "Epoch [3/5], Loss: 0.18252447969317437\n",
            "Epoch [4/5], Loss: 0.1818704092502594\n",
            "Epoch [5/5], Loss: 0.1811661997318268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_problem(model, problem):\n",
        "    model.eval()\n",
        "    input_ids = torch.tensor(tokenize_expression(problem)).unsqueeze(0)  # Add batch dimension\n",
        "    output = model(input_ids)\n",
        "    predicted_ids = output.argmax(dim=-1).squeeze().tolist()  # Get the token with the highest probability\n",
        "\n",
        "    # Decode the output tokens back to text\n",
        "    reversed_vocab = {v: k for k, v in vocab.items()}\n",
        "    solution = ' '.join([reversed_vocab[id] for id in predicted_ids if id != 0])  # Remove padding\n",
        "    return solution\n",
        "\n",
        "# Example test problem\n",
        "test_problem = \"∫(3x^2 + 2x + 1)dx\"\n",
        "solution = solve_problem(model, test_problem)\n",
        "print(f\"Problem: {test_problem}\")\n",
        "print(f\"Solution: {solution}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zop-BxWeuxs7",
        "outputId": "42b96ef3-e5c0-4450-e290-cf85d39f0fd3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem: ∫(3x^2 + 2x + 1)dx\n",
            "Solution: -9*x**4/4 - x**3/3 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"calculus_solver.pth\")"
      ],
      "metadata": {
        "id": "vR11z6mUuztO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Reward system algo + Gym API AI model with PyTorch\n"
      ],
      "metadata": {
        "id": "_3UQjsQ_21aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic test\n",
        "import sympy as sp\n",
        "import random\n",
        "\n",
        "def generate_calculus_problem():\n",
        "    x = sp.symbols('x')\n",
        "    degree = random.choice([1, 2, 3])\n",
        "\n",
        "    # Get a random polynomial\n",
        "    poly = sum(random.randint(1, 5) * x**i for i in range(degree + 1))\n",
        "\n",
        "    # Get the derivative\n",
        "    solution = sp.diff(poly, x)\n",
        "    return poly, solution\n",
        "\n",
        "# Example problem generation\n",
        "problem, solution = generate_calculus_problem()\n",
        "print(f\"Problem: {problem}\")\n",
        "print(f\"Solution (derivative): {solution}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia4dz_8f2p7p",
        "outputId": "4bd38d8d-ff09-45e2-f8e5-d1902194fe2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem: 5*x**3 + x**2 + x + 4\n",
            "Solution (derivative): 15*x**2 + 2*x + 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Gym API\n",
        "# Trying to use a reward algo\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "# Environment Class\n",
        "class CalculusEnv(gym.Env):\n",
        "    def __init__(self, reward_system):\n",
        "        super(CalculusEnv, self).__init__()\n",
        "\n",
        "        # Actions:\n",
        "        # {0: 'differentiate', 1: 'simplify', 2: 'check', 3: 'finish'}\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        # States:\n",
        "         # {0: 'in_progress', 1: 'solved'}\n",
        "        self.observation_space = spaces.Discrete(2)\n",
        "        self.reward_system = reward_system\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.problem, self.solution = generate_calculus_problem()\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.state = 0  # 'in_progress'\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, user_step=None):\n",
        "    if self.done:\n",
        "        return self.state, 0, True, {}\n",
        "\n",
        "    reward = 0\n",
        "    info = {}\n",
        "\n",
        "    if action == 0:  # Differentiate\n",
        "        if self.is_correct_step(user_step):  # Validate the differentiation step\n",
        "            reward = self.reward_system['correct_derivative']\n",
        "            self.current_step += 1\n",
        "            if self.current_step == len(str(self.solution)):\n",
        "                self.done = True\n",
        "        else:\n",
        "            reward = self.reward_system['incorrect_step']\n",
        "\n",
        "    elif action == 1:  # Simplify\n",
        "        if self.is_correct_step(user_step):  # Validate simplification\n",
        "            reward = self.reward_system['simplify']\n",
        "        else:\n",
        "            reward = self.reward_system['unnecessary_simplify']\n",
        "\n",
        "    elif action == 2:  # Check Answer\n",
        "        if user_step == self.solution:  # Validate final answer\n",
        "            self.done = True\n",
        "            reward = self.reward_system['correct_check']\n",
        "            info = {'info': 'Correct answer'}\n",
        "        else:\n",
        "            reward = self.reward_system['incorrect_check']\n",
        "\n",
        "    elif action == 3:  # Finish\n",
        "        if self.current_step == len(str(self.solution)):\n",
        "            self.done = True\n",
        "            reward = self.reward_system['finish_correct']\n",
        "            info = {'info': 'Solved'}\n",
        "        else:\n",
        "            reward = self.reward_system['finish_incorrect']\n",
        "    else:\n",
        "        reward = self.reward_system['invalid_action']\n",
        "\n",
        "    return self.state, reward, self.done, info\n",
        "\n",
        "    def render(self):\n",
        "        return f\"Current Problem: {self.problem}, Steps Taken: {self.current_step}\""
      ],
      "metadata": {
        "id": "pfdclZfa3JIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Learning Algo to train the AI\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class QLearningAgent(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(QLearningAgent, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(state_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, action_size)\n",
        "        )\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.fc(state)\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "state_size = 1  # Only one state (in_progress or solved)\n",
        "action_size = 4  # Four actions\n",
        "agent = QLearningAgent(state_size, action_size)\n",
        "\n",
        "# Initialize the target Q-value (to store the best action)\n",
        "target_q_value = QLearningAgent(state_size, action_size)\n",
        "target_q_value.load_state_dict(agent.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAPoXv5r32im",
        "outputId": "944c9fe7-15ec-4497-8ce0-f33a94917e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the AI\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "def train_agent(hyperparameters, reward_system):\n",
        "    state_size = 1\n",
        "    action_size = 4\n",
        "    agent = QLearningAgent(state_size, action_size)\n",
        "    target_q_value = QLearningAgent(state_size, action_size)\n",
        "    target_q_value.load_state_dict(agent.state_dict())\n",
        "\n",
        "    env = CalculusEnv(reward_system)\n",
        "\n",
        "    episodes = hyperparameters['episodes']\n",
        "    gamma = hyperparameters['gamma']\n",
        "    epsilon = hyperparameters['epsilon']\n",
        "    epsilon_decay = hyperparameters['epsilon_decay']\n",
        "    min_epsilon = hyperparameters['min_epsilon']\n",
        "    batch_size = hyperparameters['batch_size']\n",
        "\n",
        "    memory = deque(maxlen=10000)\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        state_tensor = torch.tensor([state], dtype=torch.float32)\n",
        "        total_reward = 0\n",
        "\n",
        "        while not env.done:\n",
        "            if random.random() < epsilon:\n",
        "                action = random.choice(range(action_size))\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    action_values = agent(state_tensor)\n",
        "                    action = torch.argmax(action_values).item()\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state_tensor = torch.tensor([next_state], dtype=torch.float32)\n",
        "\n",
        "            memory.append((state_tensor, action, reward, next_state_tensor, done))\n",
        "\n",
        "            if len(memory) >= batch_size:\n",
        "                batch = random.sample(memory, batch_size)\n",
        "                for s, a, r, ns, d in batch:\n",
        "                    q_value = agent(s)[a]\n",
        "                    target_value = r + (gamma * torch.max(target_q_value(ns)) * (1 - d))\n",
        "                    loss = nn.MSELoss()(q_value, target_value)\n",
        "\n",
        "                    agent.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    agent.optimizer.step()\n",
        "\n",
        "            state_tensor = next_state_tensor\n",
        "            total_reward += reward\n",
        "\n",
        "        if epsilon > min_epsilon:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "        target_q_value.load_state_dict(agent.state_dict())\n",
        "\n",
        "    return agent, np.mean(total_rewards[-10:])  # Return the average reward of the last 10 episodes"
      ],
      "metadata": {
        "id": "9GwKgX0O5JWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best model and params\n",
        "hyperparameter_sets = [\n",
        "    {'episodes': 100, 'gamma': 0.99, 'epsilon': 1.0, 'epsilon_decay': 0.995, 'min_epsilon': 0.1, 'batch_size': 16},\n",
        "    {'episodes': 100, 'gamma': 0.9, 'epsilon': 1.0, 'epsilon_decay': 0.99, 'min_epsilon': 0.05, 'batch_size': 32},\n",
        "]\n",
        "\n",
        "reward_systems = [\n",
        "    {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10},\n",
        "    {'correct_derivative': 15, 'step_penalty': -1, 'simplify': 1, 'unnecessary_simplify': -2, 'correct_check': 15, 'incorrect_check': -10, 'finish_correct': 15, 'finish_incorrect': -15, 'invalid_action': -15},\n",
        "]\n",
        "\n",
        "best_performance = -float('inf')\n",
        "\n",
        "for hyperparams in hyperparameter_sets:\n",
        "    for rewards in reward_systems:\n",
        "        avg_reward = train_agent(hyperparams, rewards)\n",
        "        print(f\"Hyperparams: {hyperparams}, Rewards: {rewards}, Avg Reward: {avg_reward}\")\n",
        "\n",
        "        if avg_reward > best_performance:\n",
        "            best_performance = avg_reward\n",
        "            best_hyperparams = hyperparams\n",
        "            best_reward_system = rewards\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\", best_hyperparams)\n",
        "print(\"Best Reward System:\", best_reward_system)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWUaj4yPROV8",
        "outputId": "b5f7591e-fd68-42ab-c614-d13799588965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparams: {'episodes': 100, 'gamma': 0.99, 'epsilon': 1.0, 'epsilon_decay': 0.995, 'min_epsilon': 0.1, 'batch_size': 16}, Rewards: {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10}, Avg Reward: -38.3\n",
            "Hyperparams: {'episodes': 100, 'gamma': 0.99, 'epsilon': 1.0, 'epsilon_decay': 0.995, 'min_epsilon': 0.1, 'batch_size': 16}, Rewards: {'correct_derivative': 15, 'step_penalty': -1, 'simplify': 1, 'unnecessary_simplify': -2, 'correct_check': 15, 'incorrect_check': -10, 'finish_correct': 15, 'finish_incorrect': -15, 'invalid_action': -15}, Avg Reward: -221.5\n",
            "Hyperparams: {'episodes': 100, 'gamma': 0.9, 'epsilon': 1.0, 'epsilon_decay': 0.99, 'min_epsilon': 0.05, 'batch_size': 32}, Rewards: {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10}, Avg Reward: -5.45\n",
            "Hyperparams: {'episodes': 100, 'gamma': 0.9, 'epsilon': 1.0, 'epsilon_decay': 0.99, 'min_epsilon': 0.05, 'batch_size': 32}, Rewards: {'correct_derivative': 15, 'step_penalty': -1, 'simplify': 1, 'unnecessary_simplify': -2, 'correct_check': 15, 'incorrect_check': -10, 'finish_correct': 15, 'finish_incorrect': -15, 'invalid_action': -15}, Avg Reward: -153.2\n",
            "\n",
            "Best Hyperparameters: {'episodes': 100, 'gamma': 0.9, 'epsilon': 1.0, 'epsilon_decay': 0.99, 'min_epsilon': 0.05, 'batch_size': 32}\n",
            "Best Reward System: {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best model\n",
        "hyperparameters = {'episodes': 100, 'gamma': 0.9, 'epsilon': 1.0, 'epsilon_decay': 0.99, 'min_epsilon': 0.05, 'batch_size': 32}\n",
        "rewards = {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10}\n",
        "trained_agent, rewards = train_agent(hyperparameters, rewards)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEIOmJHmVEkb",
        "outputId": "6dc69f72-94c2-4d1e-dcc7-947d99aec2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic function to test the AI\n",
        "def test_agent(agent, rewards, episodes=10):\n",
        "    env = CalculusEnv(rewards)\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        state_tensor = torch.tensor([state], dtype=torch.float32)\n",
        "        total_reward = 0\n",
        "\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                q_values = agent(state_tensor)\n",
        "                action = torch.argmax(q_values).item()\n",
        "\n",
        "            state, reward, done, info = env.step(action)\n",
        "            state_tensor = torch.tensor([state], dtype=torch.float32)\n",
        "            total_reward += reward\n",
        "\n",
        "        print(f\"Test Episode {episode + 1}/{episodes}, Total Reward: {total_reward}\")"
      ],
      "metadata": {
        "id": "vBKobGFlWQUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards = {'correct_derivative': 10, 'step_penalty': -0.5, 'simplify': 2, 'unnecessary_simplify': -1, 'correct_check': 10, 'incorrect_check': -5, 'finish_correct': 10, 'finish_incorrect': -10, 'invalid_action': -10}\n",
        "test_agent(trained_agent, rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ZC72FLACWZFX",
        "outputId": "b5fdd172-72bc-4202-fc36-64ef520756e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b95d9c94e66b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'correct_derivative'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_penalty'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'simplify'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unnecessary_simplify'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'correct_check'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'incorrect_check'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'finish_correct'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'finish_incorrect'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'invalid_action'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-f033e621f862>\u001b[0m in \u001b[0;36mtest_agent\u001b[0;34m(agent, rewards, episodes)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the AI to evaluate and understand what happened\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize accuracy over episodes\n",
        "def plot_accuracy_progress(accuracy_list):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(accuracy_list, label='Accuracy')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Agent Accuracy Over Episodes')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# accuracy_progress from earlier during training\n",
        "plot_accuracy_progress(accuracy_progress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "s9IT5cMa5frZ",
        "outputId": "ccb06027-33a2-4935-8a7f-113353767d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand what the AI is messing up\n",
        "def visualize_results(results, num_examples=5):\n",
        "    print(\"Examples of Correct Solutions:\")\n",
        "    correct_examples = [res for res in results if res[2] == \"Correct\"]\n",
        "    for i, (problem, solution, status) in enumerate(correct_examples[:num_examples]):\n",
        "        print(f\"{i + 1}. Problem: {problem}, Solution: {solution}, Status: {status}\")\n",
        "\n",
        "    print(\"\\nExamples of Incorrect Solutions:\")\n",
        "    incorrect_examples = [res for res in results if res[2] == \"Incorrect\"]\n",
        "    for i, (problem, solution, status) in enumerate(incorrect_examples[:num_examples]):\n",
        "        print(f\"{i + 1}. Problem: {problem}, Solution: {solution}, Status: {status}\")\n",
        "\n",
        "\n",
        "visualize_results(test_results)"
      ],
      "metadata": {
        "id": "7KSsTqJv5xsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Confusion Matrix just to see if we learn anything new\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(results):\n",
        "    y_true = [\"Correct\" if res[2] == \"Correct\" else \"Incorrect\" for res in results]\n",
        "    y_pred = [\"Correct\" if res[2] == \"Correct\" else \"Incorrect\" for res in results]\n",
        "\n",
        "    labels = [\"Correct\", \"Incorrect\"]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_confusion_matrix(test_results)"
      ],
      "metadata": {
        "id": "z_IaCeWo53BE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}